{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from visdom import Visdom\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "[\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10('./data',train=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10('./data',train=False, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "dataiter = iter(test_loader)\n",
    "image,label = dataiter.next()\n",
    "image = viz.images(image[:10]/2+0.5,nrow=10,padding=3)\n",
    "text=viz.text('||'.join('%6s' % classes[label[j]] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3,16,5,1,2),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "                                   \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,32,3,1,1),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.fc1 = nn.Sequential(nn.Linear(32*8*8,256),\n",
    "                                 nn.BatchNorm1d(256),\n",
    "                                 nn.ReLU(inplace=True))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(256,128),\n",
    "                                  nn.BatchNorm1d(128),\n",
    "                                  nn.ReLU(inplace=True))\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(-1,32*8*8)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "if torch.cuda.is_available:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=30,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "line = viz.line(Y=np.arange(10))\n",
    "tr_loss, ts_loss,tr_acc,ts_acc,step=[],[],[],[],[]\n",
    "best_acc = 0\n",
    "best_state = net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Train: [1/200] | loss:1.8230 | r_acc :0.3845\n",
      "Val: [1/200] | loss:1.5443 | r_acc :0.4814\n",
      "50000\n",
      "Train: [2/200] | loss:1.4065 | r_acc :0.5192\n",
      "Val: [2/200] | loss:1.2939 | r_acc :0.5526\n",
      "50000\n",
      "Train: [3/200] | loss:1.2185 | r_acc :0.5777\n",
      "Val: [3/200] | loss:1.1575 | r_acc :0.5945\n",
      "50000\n",
      "Train: [4/200] | loss:1.1007 | r_acc :0.6184\n",
      "Val: [4/200] | loss:1.0909 | r_acc :0.6223\n",
      "50000\n",
      "Train: [5/200] | loss:1.0100 | r_acc :0.6507\n",
      "Val: [5/200] | loss:1.0508 | r_acc :0.6269\n",
      "50000\n",
      "Train: [6/200] | loss:0.9376 | r_acc :0.6761\n",
      "Val: [6/200] | loss:0.9608 | r_acc :0.6666\n",
      "50000\n",
      "Train: [7/200] | loss:0.8827 | r_acc :0.6952\n",
      "Val: [7/200] | loss:0.9291 | r_acc :0.6756\n",
      "50000\n",
      "Train: [8/200] | loss:0.8329 | r_acc :0.7105\n",
      "Val: [8/200] | loss:0.9082 | r_acc :0.6816\n",
      "50000\n",
      "Train: [9/200] | loss:0.7920 | r_acc :0.7255\n",
      "Val: [9/200] | loss:0.8674 | r_acc :0.6973\n",
      "50000\n",
      "Train: [10/200] | loss:0.7546 | r_acc :0.7400\n",
      "Val: [10/200] | loss:0.8700 | r_acc :0.6966\n",
      "50000\n",
      "Train: [11/200] | loss:0.7159 | r_acc :0.7550\n",
      "Val: [11/200] | loss:0.8580 | r_acc :0.7048\n",
      "50000\n",
      "Train: [12/200] | loss:0.6868 | r_acc :0.7631\n",
      "Val: [12/200] | loss:0.8441 | r_acc :0.7035\n",
      "50000\n",
      "Train: [13/200] | loss:0.6601 | r_acc :0.7739\n",
      "Val: [13/200] | loss:0.8280 | r_acc :0.7148\n",
      "50000\n",
      "Train: [14/200] | loss:0.6261 | r_acc :0.7867\n",
      "Val: [14/200] | loss:0.8026 | r_acc :0.7186\n",
      "50000\n",
      "Train: [15/200] | loss:0.5965 | r_acc :0.7973\n",
      "Val: [15/200] | loss:0.8117 | r_acc :0.7207\n",
      "50000\n",
      "Train: [16/200] | loss:0.5743 | r_acc :0.8027\n",
      "Val: [16/200] | loss:0.8428 | r_acc :0.7106\n",
      "50000\n",
      "Train: [17/200] | loss:0.5536 | r_acc :0.8101\n",
      "Val: [17/200] | loss:0.7730 | r_acc :0.7336\n",
      "50000\n",
      "Train: [18/200] | loss:0.5260 | r_acc :0.8216\n",
      "Val: [18/200] | loss:0.7729 | r_acc :0.7330\n",
      "50000\n",
      "Train: [19/200] | loss:0.5044 | r_acc :0.8285\n",
      "Val: [19/200] | loss:0.8278 | r_acc :0.7209\n",
      "50000\n",
      "Train: [20/200] | loss:0.4835 | r_acc :0.8372\n",
      "Val: [20/200] | loss:0.7813 | r_acc :0.7332\n",
      "50000\n",
      "Train: [21/200] | loss:0.4555 | r_acc :0.8479\n",
      "Val: [21/200] | loss:0.8228 | r_acc :0.7267\n",
      "50000\n",
      "Train: [22/200] | loss:0.4428 | r_acc :0.8519\n",
      "Val: [22/200] | loss:0.8004 | r_acc :0.7320\n",
      "50000\n",
      "Train: [23/200] | loss:0.4216 | r_acc :0.8588\n",
      "Val: [23/200] | loss:0.7917 | r_acc :0.7376\n",
      "50000\n",
      "Train: [24/200] | loss:0.3981 | r_acc :0.8680\n",
      "Val: [24/200] | loss:0.8079 | r_acc :0.7302\n",
      "50000\n",
      "Train: [25/200] | loss:0.3837 | r_acc :0.8746\n",
      "Val: [25/200] | loss:0.8020 | r_acc :0.7354\n",
      "50000\n",
      "Train: [26/200] | loss:0.3627 | r_acc :0.8800\n",
      "Val: [26/200] | loss:0.8031 | r_acc :0.7344\n",
      "50000\n",
      "Train: [27/200] | loss:0.3443 | r_acc :0.8868\n",
      "Val: [27/200] | loss:0.8234 | r_acc :0.7300\n",
      "50000\n",
      "Train: [28/200] | loss:0.3299 | r_acc :0.8914\n",
      "Val: [28/200] | loss:0.8142 | r_acc :0.7366\n",
      "50000\n",
      "Train: [29/200] | loss:0.3133 | r_acc :0.8988\n",
      "Val: [29/200] | loss:0.8366 | r_acc :0.7344\n",
      "50000\n",
      "Train: [30/200] | loss:0.2975 | r_acc :0.9036\n",
      "Val: [30/200] | loss:0.8374 | r_acc :0.7342\n",
      "50000\n",
      "Train: [31/200] | loss:0.2372 | r_acc :0.9307\n",
      "Val: [31/200] | loss:0.7986 | r_acc :0.7441\n",
      "50000\n",
      "Train: [32/200] | loss:0.2206 | r_acc :0.9391\n",
      "Val: [32/200] | loss:0.7934 | r_acc :0.7428\n",
      "50000\n",
      "Train: [33/200] | loss:0.2131 | r_acc :0.9417\n",
      "Val: [33/200] | loss:0.7961 | r_acc :0.7448\n",
      "50000\n",
      "Train: [34/200] | loss:0.2078 | r_acc :0.9434\n",
      "Val: [34/200] | loss:0.8017 | r_acc :0.7437\n",
      "50000\n",
      "Train: [35/200] | loss:0.2053 | r_acc :0.9453\n",
      "Val: [35/200] | loss:0.7983 | r_acc :0.7457\n",
      "50000\n",
      "Train: [36/200] | loss:0.2006 | r_acc :0.9474\n",
      "Val: [36/200] | loss:0.8023 | r_acc :0.7444\n",
      "50000\n",
      "Train: [37/200] | loss:0.1964 | r_acc :0.9483\n",
      "Val: [37/200] | loss:0.8070 | r_acc :0.7417\n",
      "50000\n",
      "Train: [38/200] | loss:0.1951 | r_acc :0.9490\n",
      "Val: [38/200] | loss:0.8061 | r_acc :0.7466\n",
      "50000\n",
      "Train: [39/200] | loss:0.1898 | r_acc :0.9507\n",
      "Val: [39/200] | loss:0.8095 | r_acc :0.7446\n",
      "50000\n",
      "Train: [40/200] | loss:0.1873 | r_acc :0.9519\n",
      "Val: [40/200] | loss:0.8083 | r_acc :0.7434\n",
      "50000\n",
      "Train: [41/200] | loss:0.1858 | r_acc :0.9527\n",
      "Val: [41/200] | loss:0.8105 | r_acc :0.7444\n",
      "50000\n",
      "Train: [42/200] | loss:0.1806 | r_acc :0.9538\n",
      "Val: [42/200] | loss:0.8155 | r_acc :0.7422\n",
      "50000\n",
      "Train: [43/200] | loss:0.1813 | r_acc :0.9541\n",
      "Val: [43/200] | loss:0.8166 | r_acc :0.7440\n",
      "50000\n",
      "Train: [44/200] | loss:0.1785 | r_acc :0.9553\n",
      "Val: [44/200] | loss:0.8142 | r_acc :0.7443\n",
      "50000\n",
      "Train: [45/200] | loss:0.1733 | r_acc :0.9578\n",
      "Val: [45/200] | loss:0.8214 | r_acc :0.7434\n",
      "50000\n",
      "Train: [46/200] | loss:0.1693 | r_acc :0.9588\n",
      "Val: [46/200] | loss:0.8232 | r_acc :0.7400\n",
      "50000\n",
      "Train: [47/200] | loss:0.1685 | r_acc :0.9589\n",
      "Val: [47/200] | loss:0.8260 | r_acc :0.7409\n",
      "50000\n",
      "Train: [48/200] | loss:0.1681 | r_acc :0.9597\n",
      "Val: [48/200] | loss:0.8255 | r_acc :0.7441\n",
      "50000\n",
      "Train: [49/200] | loss:0.1661 | r_acc :0.9600\n",
      "Val: [49/200] | loss:0.8293 | r_acc :0.7424\n",
      "50000\n",
      "Train: [50/200] | loss:0.1639 | r_acc :0.9603\n",
      "Val: [50/200] | loss:0.8331 | r_acc :0.7403\n",
      "50000\n",
      "Train: [51/200] | loss:0.1594 | r_acc :0.9620\n",
      "Val: [51/200] | loss:0.8328 | r_acc :0.7420\n",
      "50000\n",
      "Train: [52/200] | loss:0.1606 | r_acc :0.9619\n",
      "Val: [52/200] | loss:0.8318 | r_acc :0.7411\n",
      "50000\n",
      "Train: [53/200] | loss:0.1581 | r_acc :0.9620\n",
      "Val: [53/200] | loss:0.8443 | r_acc :0.7419\n",
      "50000\n",
      "Train: [54/200] | loss:0.1567 | r_acc :0.9625\n",
      "Val: [54/200] | loss:0.8383 | r_acc :0.7426\n",
      "50000\n",
      "Train: [55/200] | loss:0.1528 | r_acc :0.9643\n",
      "Val: [55/200] | loss:0.8436 | r_acc :0.7411\n",
      "50000\n",
      "Train: [56/200] | loss:0.1520 | r_acc :0.9656\n",
      "Val: [56/200] | loss:0.8492 | r_acc :0.7409\n",
      "50000\n",
      "Train: [57/200] | loss:0.1511 | r_acc :0.9638\n",
      "Val: [57/200] | loss:0.8513 | r_acc :0.7412\n",
      "50000\n",
      "Train: [58/200] | loss:0.1490 | r_acc :0.9649\n",
      "Val: [58/200] | loss:0.8484 | r_acc :0.7424\n",
      "50000\n",
      "Train: [59/200] | loss:0.1471 | r_acc :0.9671\n",
      "Val: [59/200] | loss:0.8561 | r_acc :0.7407\n",
      "50000\n",
      "Train: [60/200] | loss:0.1453 | r_acc :0.9680\n",
      "Val: [60/200] | loss:0.8531 | r_acc :0.7411\n",
      "50000\n",
      "Train: [61/200] | loss:0.1412 | r_acc :0.9690\n",
      "Val: [61/200] | loss:0.8586 | r_acc :0.7404\n",
      "50000\n",
      "Train: [62/200] | loss:0.1403 | r_acc :0.9691\n",
      "Val: [62/200] | loss:0.8584 | r_acc :0.7418\n",
      "50000\n",
      "Train: [63/200] | loss:0.1363 | r_acc :0.9719\n",
      "Val: [63/200] | loss:0.8553 | r_acc :0.7411\n",
      "50000\n",
      "Train: [64/200] | loss:0.1388 | r_acc :0.9701\n",
      "Val: [64/200] | loss:0.8501 | r_acc :0.7418\n",
      "50000\n",
      "Train: [65/200] | loss:0.1373 | r_acc :0.9702\n",
      "Val: [65/200] | loss:0.8522 | r_acc :0.7409\n",
      "50000\n",
      "Train: [66/200] | loss:0.1392 | r_acc :0.9694\n",
      "Val: [66/200] | loss:0.8526 | r_acc :0.7442\n",
      "50000\n",
      "Train: [67/200] | loss:0.1364 | r_acc :0.9704\n",
      "Val: [67/200] | loss:0.8540 | r_acc :0.7417\n",
      "50000\n",
      "Train: [68/200] | loss:0.1378 | r_acc :0.9703\n",
      "Val: [68/200] | loss:0.8549 | r_acc :0.7395\n",
      "50000\n",
      "Train: [69/200] | loss:0.1363 | r_acc :0.9705\n",
      "Val: [69/200] | loss:0.8568 | r_acc :0.7396\n",
      "50000\n",
      "Train: [70/200] | loss:0.1378 | r_acc :0.9696\n",
      "Val: [70/200] | loss:0.8560 | r_acc :0.7420\n",
      "50000\n",
      "Train: [71/200] | loss:0.1383 | r_acc :0.9703\n",
      "Val: [71/200] | loss:0.8520 | r_acc :0.7423\n",
      "50000\n",
      "Train: [72/200] | loss:0.1384 | r_acc :0.9706\n",
      "Val: [72/200] | loss:0.8513 | r_acc :0.7417\n",
      "50000\n",
      "Train: [73/200] | loss:0.1370 | r_acc :0.9701\n",
      "Val: [73/200] | loss:0.8545 | r_acc :0.7404\n",
      "50000\n",
      "Train: [74/200] | loss:0.1360 | r_acc :0.9707\n",
      "Val: [74/200] | loss:0.8539 | r_acc :0.7411\n",
      "50000\n",
      "Train: [75/200] | loss:0.1370 | r_acc :0.9706\n",
      "Val: [75/200] | loss:0.8520 | r_acc :0.7423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5572ef3eabf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train: [{}/{}] | loss:{:.4f} | r_acc :{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(90):\n",
    "    running_loss, running_acc,img_num = 0.0,0.0,0\n",
    "    scheduler.step()\n",
    "    net.train()\n",
    "    for i,(img,label) in enumerate(train_loader,1):\n",
    "        if torch.cuda.is_available:\n",
    "            img, label = img.cuda(),label.cuda()\n",
    "        img,label = Variable(img),Variable(label)\n",
    "        output = net(img)\n",
    "        loss = criterion(output,label)\n",
    "        pred = torch.max(output,1)[1]\n",
    "        #print(pred)\n",
    "        running_acc += sum(pred==label).data[0]\n",
    "        running_loss += loss.data[0]*len(label)\n",
    "        #print(running_loss)\n",
    "        img_num += len(label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(img_num)\n",
    "    print(\"Train: [{}/{}] | loss:{:.4f} | r_acc :{:.4f}\".format(epoch+1,200,running_loss/img_num,running_acc/img_num))\n",
    "    tr_loss.append(running_loss/img_num)\n",
    "    tr_acc.append(running_acc/img_num)\n",
    "          \n",
    "    net.eval()\n",
    "    eval_loss,eval_acc,img_num=0.0,0.0,0\n",
    "    for i,(img,label) in enumerate(test_loader,1):\n",
    "        if torch.cuda.is_available:\n",
    "            img, label = img.cuda(),label.cuda()\n",
    "        img,label = Variable(img),Variable(label)\n",
    "        output = net(img)\n",
    "        loss = criterion(output,label)\n",
    "        pred = torch.max(output,1)[1]\n",
    "        eval_acc += sum(pred==label).data[0]\n",
    "        eval_loss += loss.data[0]*len(label)\n",
    "        img_num += len(label)\n",
    "          \n",
    "        \n",
    "    print(\"Val: [{}/{}] | loss:{:.4f} | r_acc :{:.4f}\".format(epoch+1,200,eval_loss/img_num,eval_acc/img_num))\n",
    "    ts_loss.append(eval_loss/img_num)\n",
    "    ts_acc.append(eval_acc/img_num)\n",
    "          \n",
    "    viz.line(Y=np.column_stack((np.array(tr_loss),np.array(tr_acc),np.array(ts_loss),np.array(ts_acc))),\n",
    "            win=line,\n",
    "            opts=dict(legend=[\"tr_loss\",\"tr_acc\",\"ts_loss\",\"ts_acc\"],title=\"cafar10\"),)\n",
    "    if eval_acc/img_num > best_acc:\n",
    "          best_acc = eval_acc/img_num\n",
    "          best_state=net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
