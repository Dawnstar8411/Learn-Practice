{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic autograd example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1]),requires_grad=True)\n",
    "w = Variable(torch.Tensor([2]),requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]),requires_grad=True)\n",
    "y = w * x + b\n",
    "y.backward()\n",
    "print(x.grad) # partial derivative\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('w: ', Parameter containing:\n",
      "-0.2663  0.5208  0.1099\n",
      "-0.1311 -0.5619 -0.4654\n",
      "[torch.FloatTensor of size 2x3]\n",
      ")\n",
      "('b: ', Parameter containing:\n",
      " 0.2685\n",
      "-0.2168\n",
      "[torch.FloatTensor of size 2]\n",
      ")\n",
      "('loss: ', 2.511803388595581)\n",
      "('dL/dw: ', Variable containing:\n",
      "-0.9917  0.5712 -0.3708\n",
      "-0.7451 -0.9118 -0.1843\n",
      "[torch.FloatTensor of size 2x3]\n",
      ")\n",
      "('dL/db: ', Variable containing:\n",
      " 0.7504\n",
      "-0.5308\n",
      "[torch.FloatTensor of size 2]\n",
      ")\n",
      "('loss after 1 step optimization: ', 2.474860191345215)\n"
     ]
    }
   ],
   "source": [
    "# create tensors\n",
    "x = Variable(torch.randn(5,3))\n",
    "y = Variable(torch.randn(5,2))\n",
    "\n",
    "# build a linear layer\n",
    "linear = nn.Linear(3,2)\n",
    "print('w: ',linear.weight)\n",
    "print('b: ',linear.bias)\n",
    "\n",
    "# build loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.01)\n",
    "\n",
    "# forward propagation\n",
    "pred = linear(x)\n",
    "\n",
    "# compute loss\n",
    "loss = criterion(pred,y)\n",
    "print('loss: ',loss.data[0])\n",
    "\n",
    "# backpropagation\n",
    "loss.backward()\n",
    "\n",
    "# print out the gradients\n",
    "print('dL/dw: ',linear.weight.grad)\n",
    "print('dL/db: ',linear.bias.grad)\n",
    "\n",
    "# 1-step Optimization(gradient descent)\n",
    "optimizer.step()\n",
    "\n",
    "# you can also do optimization as the low level as shown below\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.weight.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# print out the loss after optimization\n",
    "pred = linear(x)\n",
    "loss = criterion(pred,y)\n",
    "print('loss after 1 step optimization: ',loss.data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[2,3],[4,5]])\n",
    "b = torch.from_numpy(a) # convert numpy array to torch tensor\n",
    "c = b.numpy(b) # convert torch tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the input pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Download and construct dataset\n",
    "train_dataset = dsets.CIFAR10(root = '../data/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "# Select one data pair (read data from disk)\n",
    "image,label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)\n",
    "# Data Loader (this privides queue and thread in a very simple way)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=100,shuffle=True,num_workers=2)\n",
    "\n",
    "# When iteration starts, queue and thread start to load dataset\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels\n",
    "images,labels = data_iter.next()\n",
    "\n",
    "# Actual usage of data loader is as below\n",
    "for images,labels in train_loader:\n",
    "    # Your training code will be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input pipline for custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should build custom dataset as below\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1.Initialize file path or list of file names,\n",
    "        pass\n",
    "    def __getitem__(self,index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file(e.g. using numpy.fromfile,PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g, image and label)\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0\n",
    "# Then, you can just use prebuilt torch's data loader\n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                          batch_size = 100,\n",
    "                                          shuffle = TRUE，\n",
    "                                          num_workers = 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pretrained resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/g1002/.torch/models/resnet18-5c106cde.pth\n",
      " 92%|█████████▏| 43171840/46827520 [31:53<02:38, 23046.25it/s]"
     ]
    }
   ],
   "source": [
    "# Download and load pretrained resnet\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only top layer of the model.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features,100) # 100 is for example.\n",
    "\n",
    "# For test.\n",
    "images = Variable(torch.randn(10,3,256,256))\n",
    "outputs = resnet(images)\n",
    "print(outputs.size()) # (10,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load the entire model\n",
    "torch.save(resnet,'model.pkl')\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "# Save and load only the model parameters(recommended)\n",
    "torch.save(resnet.state_dict(),'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
