{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering a Model from PyTorch to Caffe2 and Mobile Using ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self,upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet,self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1,64,(5,5),(1,1),(2,2))\n",
    "        self.conv2 = nn.Conv2d(64,64,(3,3),(1,1),(1,1))\n",
    "        self.conv3 = nn.Conv2d(64,32,(3,3),(1,1),(1,1))\n",
    "        self.conv4 = nn.Conv2d(32,upscale_factor**2,(3,3),(1,1),(1,1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "batch_size = 1\n",
    "\n",
    "map_location = lambda storage, loc:storage\n",
    "if torch.cuda.is_available():\n",
    "    map_location = None\n",
    "torch_model.load_state_dict(model_zoo.load_url(model_url, map_location = map_location))\n",
    "\n",
    "torch_model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, 1, 224,224, requires_grad = True)\n",
    "\n",
    "# torch_out is the output after executing the model. Normally you can ignor this output.\n",
    "torch_out = torch.onnx._export(torch_model,               # Model being run\n",
    "                               x,                         # Model input or a tuple of multiple inputs\n",
    "                               \"./model/super_resolution.onnx\",   # Where to save the model\n",
    "                               export_params = True)      # Store the trained parameter weights inside the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import caffe2.python.onnx.backend as onnx_caffe2_backend\n",
    "\n",
    "# Load the ONNX ModelProto object. Model is a standard Python Protobuf Object\n",
    "model = onnx.load(\"./model/super_resolution.onnx\")\n",
    "\n",
    "# Prepare the caffe2 backend for executing the model.\n",
    "# This convert the ONNX model into a Caffe2 NetDef that can execute it.\n",
    "prepared_backend = onnx_caffe2_backend.prepare(model)\n",
    "\n",
    "W = {model.graph.input[0].name: x.data.numpy()}\n",
    "\n",
    "c2_out = prepared_backend.run(W)[0]  # run the caffe2 Net\n",
    "\n",
    "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(),c2_out, decimal=3)\n",
    "print(\"Exported model has been executed on Caffe2 backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model on Mobile Devices\n",
    "\n",
    "We will use Caffe2's `mobile_exporter` to generate the two model protobufs that can run on mobile. The first is used to initialize the network with the correct weights, and the second actual runs executes the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_workspace = prepared_backend.workspace\n",
    "c2_model = prepared_backend.predict_net\n",
    "\n",
    "from caffe2.python.predictor import mobile_exporter  # caffe mobile exporter\n",
    "\n",
    "init_net, predict_net = mobile_exploter.Export(c2_workspace, c2_model, c2_model.external_input)\n",
    "\n",
    "with open('init_net.pb',\"wb\") as fopen: # init_net has the model parameters and the model input embedded in it\n",
    "    fopen.write(init_net.SerializeToString())\n",
    "with open('predict_net.pb',\"wb\") as fopen: # predict_net will be used to guide the init_net execution at run-time\n",
    "    fopen.write(predict_net.SerializaToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import core,net_drawer,net_printer, visualize, workspace, utils\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = io.imread(\"./_static/img/cat.jpg\")\n",
    "img = transform.resize(img_in,[224,224])\n",
    "io.imsave(\"./_static/img/cat_224x224.jpg\",img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"./_static/img/cat_224x224.jpg\")\n",
    "img_ycbcr = img.convert('YCvCr')\n",
    "img_y,img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "# Let's run the mobile nets that we generated above so that caffe2 workspace is properly initialized\n",
    "workspace.RunNetOnce(init_net)\n",
    "workspace.RunNetOnce(predict_net)\n",
    "\n",
    "# Caffe2 has a nice net_printer to be able to inspect what the net looks like and identify what our input and output blob names are\n",
    "print(net_printer.to_string(predict_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's also pass in the resized cat image for processing by the model\n",
    "workspace.FeedBlob(\"9\",np.array(img_y)[np.newaxis,np.newaxis,:,:].astype(np.float32))\n",
    "\n",
    "# run the predict_net to get the model output\n",
    "workspace.RunNetOnce(predict_net)\n",
    "\n",
    "# Now let's get the model output blob\n",
    "imt_out = workspace.FetchBlob(\"27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out_y = Image.fromarray(np.unit8((img_out[0,0]).clip(0,255)),mode='L')\n",
    "\n",
    "final_img = Image.merge(\"YCbCr\",[\n",
    "    img_out_y,\n",
    "    img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "    img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "]).convert(\"RGB\")\n",
    "\n",
    "final_img.save(\"./_static/img/cat_superres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let's first push a bunch of stuff to adb, specify the path for the binary\n",
    "CAFF2_MOBILE_BINARY = ('caffe2/binaries/speed_benchmark')\n",
    "\n",
    "# we had saved our init_net and proto_net in steps above, we use them noew\n",
    "# Push the binary and the model protos\n",
    "os.system('adb push '+CAFFE2_MOBILE_BINARY + '/data/local/tmp/')\n",
    "os.system('adb push init_net.pb /data/local/tmp')\n",
    "os.system('adb push predict_net.pb /data/local/tmp')\n",
    "\n",
    "# Let's serialize the input image blob to a blob proto and then send it to mobile for execution \n",
    "with open(\"input.blobproto\", \"wb\") as fid:\n",
    "    fid.write(workspace.SerializaBlob(\"9\"))\n",
    "    \n",
    "# push the input image blob to adb\n",
    "os.system('adb push input.blobproto /dta/local/tmp')\n",
    "\n",
    "# Now we run the net on mobile, look at the spped_benchmark\n",
    "os.system('adb shell /data/local/tmp/speed_benchmark '                # binary to execute\n",
    "         '--init_net=/data/local/tmp/super_resolution_mobile_init.pb' # mobile init_net\n",
    "         '--net=/data/local/tmp/super_resolution_mobile_predict.pb '  # mobile predict_net\n",
    "         '--input=9'                                                  # name of our input image blob\n",
    "         '--input_file = /data/local/tmp/input.blobproto'             # serialized input image\n",
    "         '--output_folder = /data/local/tmp '                         # destination folder for saving mobile output\n",
    "         '--output=27.9 '                                             # output blobs we are interested in\n",
    "         '--iter=1 '                                                  # number of net iterations to execute\n",
    "         '--caffe2_log_level=0')\n",
    "\n",
    "# get the model output from adb and save to a file\n",
    "os.system('adb pull /data/local/tmp/27 ./output.blobproto')\n",
    "\n",
    "# We can recover the output content and post-process the model using same steps as we followed earlier\n",
    "blob_proto = caffe2_pb2.BlobProto()\n",
    "blob_proto.ParseFromString(open('./output.blobproto').read())\n",
    "img_out = utils.Caff2TensorToNumpyArray(blob_proto.tensor)\n",
    "img_out_y = Image.fromarray(np.unit8((img_out[0,0]).clip(0,255)),mode='L')\n",
    "final_img = Image.merge(\"YCbCr\",[\n",
    "    img_out_y,\n",
    "    img_cb.resize(img_out_y.size,Image.BICUBIC),\n",
    "    img_cr.resize(img_out_y.size,Image.BICUBIC),\n",
    "]).convert(\"RGB\")\n",
    "final_img.save(\"./_static/img/cat_superres_mobile.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
